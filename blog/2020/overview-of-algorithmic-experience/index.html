<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="google9a359609faa93abb.html"> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>An overview of Algorithmic Experience (AX) | Duy Dang-Pham</title> <meta name="author" content="Duy Dang-Pham"> <meta name="description" content="Artificial intelligence has been increasingly becoming an integral part of everyday life through a wide variety of implementations, such as e-commerce recommender systems, movie recommendations, tailored content aggregation services or navigation systems. While the rapid adoption of algorithm technologies has the potential to greatly improve users’ experience and increase services, it is still unclear how users cognitively accept such recommender systems. In other words, what factors affect our satisfaction and adoption of these algorithm recommender systems? And how could we improve users’ algorithmic experience?"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link href="/assets/css/bootstrap-toc.min.css?6f5af0bb9aab25d79b2448143cbeaa88" rel="stylesheet"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://www.drduydangpham.com/blog/2020/overview-of-algorithmic-experience/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?3dd82e91913a2c1265c0f80e41ff39e2"></script> <script src="/assets/js/dark_mode.js?6458e63976eae16c0cbe86b97023895a"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Duy </span>Dang-Pham</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">project</a> </li> <li class="nav-item "> <a class="nav-link" href="/research/">research</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/awards-and-press/">awards &amp; press</a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="row"> <div class="col-sm-3"> <nav id="toc-sidebar" class="sticky-top"></nav> </div> <div class="col-sm-9"> <div class="post"> <header class="post-header"> <h1 class="post-title">An overview of Algorithmic Experience (AX)</h1> <p class="post-meta">December 6, 2020</p> <p class="post-tags"> <a href="/blog/2020"> <i class="fas fa-calendar fa-sm"></i> 2020 </a>   ·   <a href="/blog/category/commentary"> <i class="fas fa-tag fa-sm"></i> commentary</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <p>Artificial intelligence has been increasingly becoming an integral part of everyday life through a wide variety of implementations, such as e-commerce recommender systems, movie recommendations, tailored content aggregation services or navigation systems. While the rapid adoption of algorithm technologies has the potential to greatly improve users’ experience and increase services, it is still unclear how users cognitively accept such recommender systems. In other words, what factors affect our satisfaction and adoption of these algorithm recommender systems? And how could we improve users’ algorithmic experience?</p> <h3 id="the-problem-of-ai-from-users-perspectives">The problem of AI: from users’ perspectives</h3> <p>By analysing 35,448 users’ reviews towards Facebook, Netflix and Google Maps, Eiband et al. (2019) have explored that not only accuracy but the interaction between users and systems also influences users’ experience. On the one hand, this study suggests that algorithmic and knowledge-based problems such as biased content curation (Facebook), the mismatch between recommendations and user interest (Netflix) or inaccurate destination (Google Maps) are common problems of these systems. On the other hand, users may feel annoyed when they have limited control over the way systems work (user choice). For example, users may feel disappointed when Google Maps keeps overwriting their manually selected routes without informing them. In addition, the way systems interact with users’ feedback is also important. With the binary rating system (like/ dislike), users may struggle to provide meaningful feedback to Netflix, which in turn affects the relevance of recommendations.</p> <p>Given these human-centered problems, a growing body of research starts to explore “algorithmic experience” or “AX” (Alvarado &amp; Waern 2018) – an overarching view on user interaction with intelligent systems. This notion includes the effort of fostering user control over algorithmic decision making, transparently increasing the awareness of how the system works and deliberately activating or deactivating algorithmic influence.</p> <h3 id="algorithmic-experience-and-user-control">Algorithmic experience and user control</h3> <p>Human agency and oversight over the system is one of the emerging topics. By allowing users to corroborate, manage and stay in control of the algorithm, the system can make users feel empowered and capable of managing what the system thinks about them (Alvarado &amp; Waern 2018; Kumar et al. 2020). According to the survey, 56% of users wish they could have options to control Facebook newsfeed and filter the content themselves, by turning on/ off/ adjusting People You May Know function for example (Alvarado &amp; Waern 2018). In the same vein, researchers have suggested the participation of humans in the process of designing AI systems. Engaging end-users in the developing process may improve users’ perceived fairness and trust, increase algorithm awareness and understanding of algorithmic decision making, thus lead to a more empathetic stance (Lee et al. 2019).</p> <h3 id="algorithmic-experience-and-transparency">Algorithmic experience and transparency</h3> <p>Recent research on algorithmic adoption and algorithmic behavioural actions have drawn on perceived transparency and fairness to explain users’ attitudes, actual use, level of acceptance, satisfaction and continue intention (Shin 2020; Shin, Zhong &amp; Biocca 2020). Transparency refers to how the system makes visible what the algorithm knows about a user and explains why the algorithm present results based on that profiling (Alvarado &amp; Waern 2018), which in turn improve the algorithmic experience. In the same vein, Shin’s (2020) trust feedback loop also suggests that perceived transparency and accuracy would assure trust, which in turn facilitates intention and satisfaction.</p> <h3 id="algorithmic-experience-and-algorithmic-awareness-the-use-of-explanation">Algorithmic experience and algorithmic awareness: the use of explanation</h3> <p>Another substantial body of work focuses on helping users make sense of intelligent systems, for example through explanations. Such explanations often target the algorithmic decision-making process or a particular output instance. On one the hand, some authors agree that the explanation positively influences perceived transparency (Brunk, Mattern &amp; Riehle 2019). On the other hand, others argue that the effectiveness of explanation depends on the transparency mechanisms (awareness, correctness, accountability, and interpretability) as well as how the system explains (Rader, Cotter &amp; Cho 2018). For example, differences towards explanation styles (input influence, sensitivity, case-based or demographic), delivery methods and modalities also affect the users’ perception of justice differently (Binns et al. 2018).</p> <h3 id="in-conclusion">In conclusion…</h3> <p>Algorithms are becoming an integral part of most everyday services, in which algorithm experience is becoming an emerging topic to approach human-centered AI. In other words, creating AI from the perspective of what satisfies human and societal needs are far more concerned, instead of pushing what is technically possible.</p> <p>Recent research has explored different ways to increase users’ satisfaction and adoption towards AI, including improving users’ participation, increasing transparency, fairness or using explanation. However, there is still limited understanding towards the possible solutions, which call for further examination and attention. By understanding the user cognition and perception, future work could be dedicated to design insightful human-centred algorithm systems. Algorithms that are user-centered will be key to designing such human-centered systems.</p> <p>Written by Diem-Trang Vo</p> <p>Edited by Duy Dang-Pham</p> <h3 id="references">References</h3> <p>Alvarado, O &amp; Waern, A 2018, ‘Towards algorithmic experience: Initial efforts for social media contexts’, in Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems, pp. 1-12.</p> <p>Binns, R, Van Kleek, M, Veale, M, Lyngs, U, Zhao, J &amp; Shadbolt, N 2018, ‘‘It’s Reducing a Human Being to a Percentage’ Perceptions of Justice in Algorithmic Decisions’, in Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems, pp. 1-14.</p> <p>Brunk, J, Mattern, J &amp; Riehle, DM 2019, ‘Effect of Transparency and Trust on Acceptance of Automatic Online Comment Moderation Systems’, in 2019 IEEE 21st Conference on Business Informatics (CBI), vol. 1, pp. 429-35.</p> <p>Eiband, M, Völkel, ST, Buschek, D, Cook, S &amp; Hussmann, H 2019, ‘When people and algorithms meet: user-reported problems in intelligent everyday applications’, in Proceedings of the 24th International Conference on Intelligent User Interfaces, pp. 96-106.</p> <p>Kumar, A, Braud, T, Tarkoma, S &amp; Hui, P 2020, ‘Trustworthy AI in the Age of Pervasive Computing and Big Data’, arXiv preprint arXiv:2002.05657.</p> <p>Lee, MK, Kusbit, D, Kahng, A, Kim, JT, Yuan, X, Chan, A, See, D, Noothigattu, R, Lee, S &amp; Psomas, A 2019, ‘WeBuildAI: Participatory framework for algorithmic governance’, Proceedings of the ACM on Human-Computer Interaction, vol. 3, no. CSCW, pp. 1-35.</p> <p>Rader, E, Cotter, K &amp; Cho, J 2018, ‘Explanations as mechanisms for supporting algorithmic transparency’, in Proceedings of the 2018 CHI conference on human factors in computing systems, pp. 1-13.</p> <p>Shin, D 2020, ‘How do users interact with algorithm recommender systems? The interaction of users, algorithms, and performance’, Computers in Human Behavior, p. 106344.</p> <p>Shin, D, Zhong, B &amp; Biocca, FA 2020, ‘Beyond user experience: What constitutes algorithmic experiences?’, International Journal of Information Management, vol. 52, p. 102061.</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2021/tong-quan-trai-nghiem-thuat-toan/">Tổng quan về trải nghiệm thuật toán (AX)</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2022/phd-scholarship-at-rmit-vietnam/">Full scholarships for PhD research in digital transformation and cybersecurity management areas at RMIT Vietnam</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2020/streamlit-for-data-app/">Streamlit for data app</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2020/analyze-apple-health-data/">Analyzing Apple Health data</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/chatgpt-ben-tre/">Ứng dụng ChatGPT cho doanh nghiệp vừa và nhỏ (SMEs) tại Bến Tre 2023</a> </li> </div> </div> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2023 Duy Dang-Pham. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="/assets/js/bootstrap-toc.min.js?c82ff4de8b0955d6ff14f5b05eed7eb6"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=UA-80767582-4"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","UA-80767582-4");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>